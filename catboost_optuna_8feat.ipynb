{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedd1fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from catboost import CatBoostRegressor\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b554db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure problem number\n",
    "PROBLEM_NUM = 36\n",
    "\n",
    "X_path = f\"./data_31_40/problem_{PROBLEM_NUM}/dataset_{PROBLEM_NUM}.csv\"\n",
    "y_path = f\"./data_31_40/problem_{PROBLEM_NUM}/target_{PROBLEM_NUM}.csv\"\n",
    "Xeval_path = f\"./data_31_40/problem_{PROBLEM_NUM}/EVAL_{PROBLEM_NUM}.csv\"\n",
    "\n",
    "X = pd.read_csv(X_path)\n",
    "y = pd.read_csv(y_path)\n",
    "X_eval = pd.read_csv(Xeval_path)\n",
    "\n",
    "y1 = y[\"target01\"]\n",
    "\n",
    "print(f\"Problem {PROBLEM_NUM}\")\n",
    "print(f\"X: {X.shape}, y1: {y1.shape}, X_eval: {X_eval.shape}\")\n",
    "\n",
    "# Create train/validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y1, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain/Val Split:\")\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4808af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 8 features by training a quick baseline model\n",
    "print(\"Training baseline model to extract top 8 features...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "model_baseline = CatBoostRegressor(\n",
    "    iterations=500,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "model_baseline.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importance = model_baseline.get_feature_importance()\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Extract top 8 features\n",
    "top_8_features = importance_df.head(8)['feature'].tolist()\n",
    "\n",
    "print(\"\\nTop 8 Features Selected:\")\n",
    "print(\"=\"*80)\n",
    "for i, feat in enumerate(top_8_features, 1):\n",
    "    imp = importance_df[importance_df['feature'] == feat]['importance'].values[0]\n",
    "    print(f\"{i}. {feat:<20} (importance: {imp:.4f})\")\n",
    "\n",
    "# Create subsets with only top 8 features\n",
    "X_train_top8 = X_train[top_8_features]\n",
    "X_val_top8 = X_val[top_8_features]\n",
    "X_eval_top8 = X_eval[top_8_features]\n",
    "\n",
    "print(f\"\\nSubset shapes:\")\n",
    "print(f\"X_train_top8: {X_train_top8.shape}\")\n",
    "print(f\"X_val_top8: {X_val_top8.shape}\")\n",
    "print(f\"X_eval_top8: {X_eval_top8.shape}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb8e913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Optuna objective function\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 500, 2000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.5, 1.0),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-2, 10.0, log=True),\n",
    "        'random_strength': trial.suggest_float('random_strength', 0.0, 2.0),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 10.0),\n",
    "        'random_state': 42,\n",
    "        'verbose': 0\n",
    "    }\n",
    "    \n",
    "    # Train model with suggested parameters\n",
    "    model = CatBoostRegressor(**params)\n",
    "    \n",
    "    model.fit(\n",
    "        X_train_top8, y_train,\n",
    "        eval_set=(X_val_top8, y_val),\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    y_val_pred = model.predict(X_val_top8)\n",
    "    val_r2 = r2_score(y_val, y_val_pred)\n",
    "    \n",
    "    return val_r2  # Maximize validation RÂ²\n",
    "\n",
    "print(\"Objective function defined.\")\n",
    "print(\"Ready to run Optuna optimization...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a057b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Optuna optimization\n",
    "print(\"=\"*80)\n",
    "print(\"STARTING OPTUNA OPTIMIZATION (8 FEATURES ONLY)\")\n",
    "print(\"=\"*80)\n",
    "print(\"Objective: Maximize Validation RÂ²\")\n",
    "print(f\"Features: {len(top_8_features)}\")\n",
    "print(f\"Trials: 150\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create study\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',  # Maximize RÂ²\n",
    "    sampler=TPESampler(seed=42),\n",
    "    study_name='catboost_optuna_8feat_p36'\n",
    ")\n",
    "\n",
    "# Optimize\n",
    "study.optimize(objective, n_trials=150, show_progress_bar=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OPTIMIZATION COMPLETE!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d10227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display best results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BEST TRIAL RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Best Trial Number: {study.best_trial.number}\")\n",
    "print(f\"Best Validation RÂ²: {study.best_value:.6f}\")\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(\"-\"*80)\n",
    "for param, value in study.best_params.items():\n",
    "    print(f\"{param:<25} {value}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226592bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model with best parameters\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING FINAL MODEL WITH BEST PARAMETERS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "best_params = study.best_params.copy()\n",
    "best_params['random_state'] = 42\n",
    "best_params['verbose'] = 100\n",
    "\n",
    "model_best = CatBoostRegressor(**best_params)\n",
    "\n",
    "model_best.fit(\n",
    "    X_train_top8, y_train,\n",
    "    eval_set=(X_val_top8, y_val),\n",
    "    early_stopping_rounds=50,\n",
    "    plot=False\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Training Complete!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396943a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate final model\n",
    "y_train_pred = model_best.predict(X_train_top8)\n",
    "y_val_pred = model_best.predict(X_val_top8)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL MODEL PERFORMANCE (8 FEATURES, OPTUNA OPTIMIZED)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Metric':<20} {'Train':<15} {'Validation':<15} {'Gap':<15}\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'RÂ²':<20} {train_r2:<15.6f} {val_r2:<15.6f} {train_r2 - val_r2:<15.6f}\")\n",
    "print(f\"{'RMSE':<20} {train_rmse:<15.6f} {val_rmse:<15.6f} {val_rmse - train_rmse:<15.6f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if val_rmse - train_rmse > 0.05:\n",
    "    print(\"\\nâš ï¸ Warning: Model shows signs of overfitting (RMSE gap > 0.05)\")\n",
    "else:\n",
    "    print(\"\\nâœ“ Excellent generalization achieved (RMSE gap < 0.05)\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Model Summary:\")\n",
    "print(f\"   Features used: {len(top_8_features)} / 273 ({len(top_8_features)/273*100:.1f}%)\")\n",
    "print(f\"   Validation RÂ²: {val_r2:.6f}\")\n",
    "print(f\"   Validation RMSE: {val_rmse:.6f}\")\n",
    "print(f\"   Trials completed: {len(study.trials)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667073c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize optimization history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Optimization history\n",
    "trial_numbers = [trial.number for trial in study.trials]\n",
    "trial_values = [trial.value for trial in study.trials]\n",
    "\n",
    "axes[0].plot(trial_numbers, trial_values, marker='o', linestyle='-', alpha=0.6, markersize=4)\n",
    "axes[0].axhline(y=study.best_value, color='red', linestyle='--', linewidth=2, label=f'Best RÂ²: {study.best_value:.6f}')\n",
    "axes[0].set_xlabel('Trial Number', fontsize=12)\n",
    "axes[0].set_ylabel('Validation RÂ²', fontsize=12)\n",
    "axes[0].set_title('Optuna Optimization History', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Parameter importance (if available)\n",
    "try:\n",
    "    param_importance = optuna.importance.get_param_importances(study)\n",
    "    params = list(param_importance.keys())\n",
    "    importances = list(param_importance.values())\n",
    "    \n",
    "    axes[1].barh(params, importances)\n",
    "    axes[1].set_xlabel('Importance', fontsize=12)\n",
    "    axes[1].set_title('Hyperparameter Importance', fontsize=14, fontweight='bold')\n",
    "    axes[1].grid(axis='x', alpha=0.3)\n",
    "except:\n",
    "    axes[1].text(0.5, 0.5, 'Parameter importance\\nrequires multiple trials', \n",
    "                ha='center', va='center', fontsize=12)\n",
    "    axes[1].set_xlim(0, 1)\n",
    "    axes[1].set_ylim(0, 1)\n",
    "    axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Visualization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac34e778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on evaluation set\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Generating predictions on evaluation set...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "eval_pred = model_best.predict(X_eval_top8)\n",
    "\n",
    "# Save predictions\n",
    "output_filename = f\"EVAL_target01_{PROBLEM_NUM}_catboost_optuna_8feat.csv\"\n",
    "submission = pd.DataFrame({\"target01\": eval_pred})\n",
    "submission.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"\\nâœ“ Saved: {output_filename}\")\n",
    "print(f\"Predictions shape: {eval_pred.shape}\")\n",
    "print(f\"Predictions range: [{eval_pred.min():.6f}, {eval_pred.max():.6f}]\")\n",
    "print(f\"\\nExpected Test RMSE: ~{val_rmse:.6f} (based on validation)\")\n",
    "print(f\"\\nFeatures used:\")\n",
    "for i, feat in enumerate(top_8_features, 1):\n",
    "    print(f\"  {i}. {feat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eae637f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top 10 trials\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 10 TRIALS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "trials_df = study.trials_dataframe()\n",
    "trials_df = trials_df.sort_values('value', ascending=False).head(10)\n",
    "\n",
    "# Show only trial number and value\n",
    "print(trials_df[['number', 'value']].to_string(index=False))\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
